---
title: AB_Omok
date: 2025-04-13
links:
  - name: Omok github link
    url: https://github.com/yeeuneey/AB_Omok.git
    icon: link
tags:
  - Ai
  - Python
---

AB_Omok을 해결하는 탐색 알고리즘을 구현하는 프로젝트.

<!--more-->

<div style="text-align: center; margin: 28px 0;">
  <a href="/uploads/omok-report.pdf" download class="hb-btn">
    <svg xmlns="http://www.w3.org/2000/svg" fill="none"
         viewBox="0 0 24 24" stroke="currentColor">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
            d="M4 16v2a2 2 0 002 2h12a2 2 0 002-2v-2M7 10l5 5 5-5M12 15V3" />
    </svg>
    보고서 PDF 다운로드
  </a>
</div>

초기의 user_agent.py 파일은 돌의 위치를 무작위로 정하여 랜덤의 수를 두는 플레이를 하였습니다. 이는 전략이 없는 무의미한 방식으로, 오목이라는 게임의 진행과는 거리가 멀었습니다. 특별한 기능이 구현되어 있지 않기 때문에 승리하는 조건이나 패배하는 조건, 또는 흰 돌의 수에 대한 방어, 연속되게 놓아진 돌의 수 계산 등이 전혀 고려되지 않은 코드였습니다. HUMAN=True일 때, 흰 돌(내가 직접 플레이)이 연속 3개의 돌을 놓는다면 방어를 하고, 방어를 하는 것뿐만 아니라 검은 돌(ai의 플레이)이 연속 5개의 돌을 놓도록(검은 돌이 승리하도록) 시도하게끔 구현하였습니다. 돌을 두는 방식은 무작위로 두는 것이 아닌, alpha-beta pruning 탐색을 기반으로 하여서 최선의 선택을 하게 됩니다. 이 알고리즘은 AI가 앞의 수까
지 탐색하며 최선의 수를 선택할 수 있도록 하는 핵심 로직입니다. 

alpth-beta pruning 구현 설명 전 점수를 내는 방식을 사용한 부분을 설명하겠습니다. 현재 게임 상태에 대한 evaluate 함수를 통해 오목판 위에서의 가능한 5칸의 연속 line에 대한 분석을 기반으로 전체 점수를 산출하는 방식입니다. evaluate 함수는 오목판을 전 방향인 가로, 세로, 오른쪽 대각선, 왼쪽 대각선을 스캔을 합니다. 각각 5칸의 연속된 line을 추출한 후에 이를 evaluate_line 함수를 통해 평가 점수를 얻어냅니다. 이 점수들을 누적해서 전체 오목판 상태의 종합 점수를 산출합니다. evaluate_line 함수는 돌의 배치를 보고 다음과 같이 점수를 부여합니다.
 -black의 5목 완성: AI가 승리한 경우 -> +100,000
 -white의 5목 완성: 대결 상대가 승리한 경우 -> -100,000
 -black의 4목: AI가 한 수만 더 두면 승리할 수 있는 경우 -> +15,000
 -white의 4목: 대결 상대가 한 수만 더 두면 승리할 수 있는 경우 -> -50,000
 -black의 3목: AI가 3목을 완성한 경우 -> +3,000
 -white의 3목: 대결 상대가 3목을 완성한 경우 -> -25,000
 -기타: 의미가 있는 수가 아닌 경우 -> 0

점수 부여는 몇 번의 시뮬레이션 과정을 통해 오목의 룰에 의한 의도대로 동작할 수 있는 제일 적정의 점수 값을 부여하였습니다. 예를 들어서 AI가 4목을 만드는 상황보다 대결 상대가 4목을 만들었을 때가 더 큰 영향력을 가진다는 것을 생각하여서 패배하는 것에서 먼저 벗어나는 것을 선택하게끔 수를 두게 하였습니다. 공격보다는 방어를 우선적으로 설계했음을 의미합니다. 이는 act 함수 내에서 상대의 3목이나 4목을 탐지하여 해당 위치에 돌을 놓도록 구현한 것과 일맥상통하는 부분이라고 할 수 있습니다.

user_agent.py와 ai_agent.py가 서로 대전하도록 했을 때 ai_agent.py는 무작위로 돌을 놓는 것에 반해 user_agent.py는 alpha-beta pruning 방식으로 동작하면서 방어를 우선적으로 합니다. 대결 상대가 놓는 연속 3개의 돌이나 4개의 돌의 위협을 탐지할 수 있고 그것을 차단하는 수를 둡니다. 그 과정에서 기회가 있을 때는 공격을 하는 수를 둡니다. 이를 종합해보면 결론적으로 user_agent.py가 더 전략적으로 탐색을 하기 때문에 win에 더 우세한, 고도화된 AI라고 볼 수 있습니다. ai_agent.py는 특별한 전략이 없이 동작하기 때문에 당연히 수 싸움에서 밀릴 수밖에 없고 이것은 곧 패배할 확률이 높은 결과로 다가오게 됩니다.

백업 수를 제공하는 것은 AI가 비정상적인 timeout이 발생하더라도 항상 안전하고 의미 있는 수를 둘 수 있게 하고, 이것은 고능한 플레이를 계속 진행하도록 돕습니다.
 ❶ 중앙 위치가 비어 있는 경우, 그 위치에 돌을 둡니다. 이는 중앙 위치를 장악하는 것은 이기기 위한 플레이에서 전략적인 선택이라고 생각하였습니다.
 ❷ 중앙을 기준으로 잡고 그 주변을 확장하며 빈 칸을 탐색합니다.
 ❸ 이 이후에는 오목판 전체를 순차적으로 스캔하면서 비어 있는 아무 칸이라도 찾아내서 반환합니다. 최후의 선택이라고 할 수 있습니다.
이렇게 timeout이 발생했을 때 대응하는 방식을 이기기 위한 전략과 완전히 무관한 위치에 수를 두는 것보다는 중앙에서 중앙의 주변으로 확대하고, 오목판 전체로 더 확대하는 우선순위를 가짐으로써 최대한 전략적으로 접근할 수 있도록 코드를 개선하였습니다. 이로써 비정상적인 판단을 방지하고 안정성이 높아짐을 확인할 수 있습니다.

또한 탐색 노드 수를 줄이기 위한 방안으로 get_candidate_moves 함수를 구현하였습니다. 이 함수는 현재 상태에서 둘 수 있는 수 중에서 의미 있는 후보 수들만 추리는 것입니다. 비어 있는 칸 중에 주변의 8칸 중 대결 상대의 돌이나 자신의 돌이 2개 이상 있을 경우에 후보로 추가합니다. 아무런 후보가 없다면 중앙 또는 중앙 주변으로 확장시키면서 그 중 빈 칸들만 후보로 뽑도록 하였습니다. 이를 통해 실제 탐색 공간을 오목판 전체가 아니라 수를 두었을 때 의미가 있는 수가 되도록 성능을 최적화하였습니다.